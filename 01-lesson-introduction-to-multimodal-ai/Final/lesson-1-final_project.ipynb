{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9387b5d3-5fa8-4f7d-b132-69836cb36103",
   "metadata": {},
   "source": [
    "# Lesson 1 Project: Introduction to Multimodal AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2680ef-279e-48ef-8656-aeb06f50b5ab",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211ef77-658d-4836-aea6-f5c39b1f0d59",
   "metadata": {},
   "source": [
    "Welcome to the first lesson on multimodal AI! While this course primarily focuses on images and speech, it also involves working with text. You should have already learned about text generation in previous courses and how to access the OpenAI text generation API. However, it never hurts to refresh your memory. By the end of this lesson, you will be able to:\n",
    "- Access the OpenAI text generation API\n",
    "- Ensure that the API responses are structured outputs\n",
    "\n",
    "These skills will serve as the foundation for learning the multimodal AI system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f6da9-561f-4f34-9ede-f1161eb3fb47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setting Up OpenAI Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71abf15-6034-42b8-8aca-228e2f1a6c7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install openai pydantic python-dotenv matplotlib Pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4890826-33ca-4c67-9952-8545fb403a3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the OpenAI library\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up relevant environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create the OpenAI connection object\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aac8c6-c445-4f01-af26-0de83cbc7203",
   "metadata": {},
   "source": [
    "## Making an API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05796a96-e70b-4735-8ec6-d469c278c9ba",
   "metadata": {},
   "source": [
    "To make a request to the OpenAI text generation API, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4de9e5-7168-443f-8a95-849181db4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an API request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an English grammar checker.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Check the grammar: 'Alice eat an apple every day.'\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03039f-7736-42c4-926f-22f9db014ae4",
   "metadata": {},
   "source": [
    "## Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eede58-e60d-4bfd-b803-12026cc3e7da",
   "metadata": {},
   "source": [
    "OpenAI introduced structured outputs, allowing you to enforce that the generated response from the API adheres to a JSON schema. This makes it easier to extract information without having to parse a raw string. To create an API request with structured outputs, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e53df-0a30-4c16-bb22-fcb23a6dbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pydantic\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Define data structure\n",
    "class GrammarChecking(BaseModel):\n",
    "    wrong_sentence: str\n",
    "    correct_sentence: str\n",
    "    is_correct: bool\n",
    "\n",
    "# Make an API request\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an English grammar checker.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Check the grammar: 'Alice eat an apple every day.'\"},\n",
    "    ],\n",
    "    response_format=GrammarChecking,\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48925aec-2ecf-40ab-a012-19f59117276b",
   "metadata": {},
   "source": [
    "## Multimodal AI API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba44e04-72ff-449b-85eb-10245fe720fd",
   "metadata": {},
   "source": [
    "But text is boring. That's why this multimodal AI are interesting. You can do so much more than text, such as generating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81461ff0-4095-4e40-abe9-a610662e2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lines\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Creating a multimodal AI API request\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"A cat holding a sign 'Welcome to the Multimodal AI Module'\"\n",
    ")\n",
    "\n",
    "# Downloading the image\n",
    "image_url = response.data[0].url\n",
    "image_response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(image_response.content))\n",
    "\n",
    "# Displaying the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a1fd6-0ee7-4d9f-9b36-59a8c2bb73af",
   "metadata": {},
   "source": [
    "You would see a cute cat holding a sign \"Welcome to the Multimodal AI Module\"!\n",
    "\n",
    "Don't worry about the code. You'll learn how to craft the code to interact with the multimodal AI later in other lessons.\n",
    "\n",
    "The multimodal AI is also more than just text and images. It deals with audio as well. You'll also learn about this next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

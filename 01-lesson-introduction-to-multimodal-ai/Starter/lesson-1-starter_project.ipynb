{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9387b5d3-5fa8-4f7d-b132-69836cb36103",
   "metadata": {},
   "source": [
    "# Lesson 1 Project: Introduction to Multimodal AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2680ef-279e-48ef-8656-aeb06f50b5ab",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0211ef77-658d-4836-aea6-f5c39b1f0d59",
   "metadata": {},
   "source": [
    "Welcome to the first lesson on multimodal AI! While this course primarily focuses on images and speech, it also involves working with text. You should have already learned about text generation in previous courses and how to access the OpenAI text generation API. However, it never hurts to refresh your memory. By the end of this lesson, you will be able to:\n",
    "- Access the OpenAI text generation API\n",
    "- Ensure that the API responses are structured outputs\n",
    "\n",
    "These skills will serve as the foundation for learning the multimodal AI system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f6da9-561f-4f34-9ede-f1161eb3fb47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Setting Up OpenAI Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71abf15-6034-42b8-8aca-228e2f1a6c7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4890826-33ca-4c67-9952-8545fb403a3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the OpenAI library\n",
    "# Set up relevant environment variables\n",
    "# Create the OpenAI connection object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aac8c6-c445-4f01-af26-0de83cbc7203",
   "metadata": {},
   "source": [
    "## Making an API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05796a96-e70b-4735-8ec6-d469c278c9ba",
   "metadata": {},
   "source": [
    "To make a request to the OpenAI text generation API, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4de9e5-7168-443f-8a95-849181db4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an API request\n",
    "# Print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e03039f-7736-42c4-926f-22f9db014ae4",
   "metadata": {},
   "source": [
    "## Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eede58-e60d-4bfd-b803-12026cc3e7da",
   "metadata": {},
   "source": [
    "OpenAI introduced structured outputs, allowing you to enforce that the generated response from the API adheres to a JSON schema. This makes it easier to extract information without having to parse a raw string. To create an API request with structured outputs, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e53df-0a30-4c16-bb22-fcb23a6dbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pydantic\n",
    "# Define data structure\n",
    "# Make an API request\n",
    "# Print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b6234-eea9-4bf2-b858-a0f66d400627",
   "metadata": {},
   "source": [
    "## Multimodal AI API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4959be7-be33-4119-a8be-e922cf0a79df",
   "metadata": {},
   "source": [
    "But text is boring. That's why this multimodal AI are interesting. You can do so much more than text, such as generating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f620a-0625-41af-a00c-8297f9731363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lines\n",
    "# Creating a multimodal AI API request\n",
    "# Downloading the image\n",
    "# Displaying the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd9e53-e0f1-4b38-87a9-328ce7e608c4",
   "metadata": {},
   "source": [
    "You would see a cute cat holding a sign \"Welcome to the Multimodal AI Module\"!\n",
    "\n",
    "Don't worry about the code. You'll learn how to craft the code to interact with the multimodal AI later in other lessons.\n",
    "\n",
    "The multimodal AI is also more than just text and images. It deals with audio as well. You'll also learn about this next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef41d50-496b-45b9-b00e-7bd99e2925a2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096a17e-b465-4bb7-b6cc-4ee66f5cf8a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this lesson, you’ve refreshed your knowledge of the OpenAI text generation API. You’ve learned how to:\n",
    "- Set up the OpenAI client\n",
    "- Make an API request\n",
    "- Use structured outputs\n",
    "\n",
    "Although this multimodal AI course focuses on working with images and audio, you’ll also need to work with text. Text is an essential component of multimodal AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
